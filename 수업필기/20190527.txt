오전 10:35 2019-05-27

[Formatting and Source Coding]

컴퓨터에서 어떻게 영상, 사진, 문자 등이 다뤄질 수 있나? 
어떻게 표현되며, 어떻게 압축될 수 있나? 를 궁금해 하면 이 장이 도움이 됨.

p3
Digital info -> Digital Data
데이터를 컴퓨터에서 어떻게 표현하나

ex) 2의 보수 
5 : 0000 0101
-5 : 1111 1011

10.27 --> 1*10^1 + 0*10^0 + 2*10^-1 + 7*10^-2
10.1010 --> 

캐릭터 A 즉, 문자는 어떻게 표현할 것인가?
아스키코드 --> 코딩

한글도 한글코드가 있음.

저장할때 ANSI, 유니코드, UTF-8의 인코딩이 있음
셋 중에 뭘로 인코딩하느냐에 따라서 크기가 달라짐.
같은 '애국가에' 대해 각각 6, 8, 12 bytes를 가짐

p5
한글의 경우는 초성 + 중성 + 종성을 조합해야하는데
조합형과 완성형이 논쟁이있었음. 
그러나 한글 창제원리는 조합형에 부합함.

장점이자 단점인데, 한글을 표현하는 방법은 한가지가 아님.
그래서 한글이 깨지는 경우가 발생.
한글만의 문제는 아님. 

전세계 언어를 표현하기 위해서 유니코드가 나옴.
처음 시작은 16비트. 전세계어를 다 표현해야하니까 어느정도는 비트가 많아야한다고 생각했기때문.
FFFF //16bit
앞의 8bit에 따라 언어가 결정됨
ex) 00이면 라틴어
	아스키 : 0x41 --> 유니코드 : 0x0041
유니코드에서 한글이 상당히 많은 영토를 차지하면서(?) 좋은 방향으로 발전함.

왜 한가지로 표현되는 것이 아닐까? 그리고 인터넷은 하나인데 어떻게 보낼까?
에 대해 생각해볼 것임.

p3
MIDI
음악인데도 아날로그가 아닌 디지털 정보임.
실제 소리를 저장하는것이 아니라 키를 저장하는 것임.

p8
아날로그 정보 -> 디지털 데이터

p7
Data Acquisition System
핵심 요소 : DAC/ADC
physical Phenomena

p8~p10
PCM(Pulse Coded Modulation)
Sampling : 특정 간격마다 값을 구하는것.
Quantization : 이렇게 구해진 샘플 값에 대해서, 값을 특정한 값에 매핑하는 거

p9아래에 그림을 이해
Encoding : Qauntization결과로 나온 결과를 이진값으로 변환하는것
**괄호 채우기
Sampling 
Quantization

각각에 대해서 중요한 사람을 알아봄
 Sampling: Nyquist

If a signal is sampled at regular intervals at a rate higher than *twice the highest signal frequency, the samples contain all the information of the original signal

최고 주파수가 f라고 하면 2배~~.
sampling에서 information loss가 발생하나? 
Nyquist 이론을 만족하면, (2배 이하면) 발생하지 않음

그에 비해서 quantization은
매핑시에 information loss가 발생함. 
quantization은 항상 발생.
에러를 줄이려면 비트와 코드의 개수는 늘어남.(촘촘히 만들어서 해결)

p11 
48Khz : sample의 개수가 48000개. 
--> 1초동안 : 48000 * 16 bits/sample 
 768000bit/sec 양의 정보가 만들어짐.
이걸 한시간 동안 녹음하면 5529600000인데 
bytes단위로 보기위해 8로 나누면, 691200000 대략, 690MB.
Audio CD는 약 700MB쯤되는데, 앞서 나온 결과와 거의 비슷.
40KHz이상이 있으면 사람이 들을 수있는 소리를 샘플링하고 복원이 가능함. 

그래서 오디오 같은건 sampling * quantization으로 구할수있음.
근데, 화소/픽셀 
~ 졸고있어. 
레졸루션이 왜 컴터공학자에게 문제가 되나?

정보의 양은 너무 많고 압축은 피할수가 없음.(상식)

p13
오디오 압축기술로 아는거 mp3
상당수의 음악을 AAC라는 기술로 듣고있음.
그 외에도 있음.

오디오 압축은 크게 두가지 카테고리로 나뉨.
1. 스피치 코딩
	내가 지금 전화를 했을 때, 말하는 것이 압축되는거.
	압축률이 아주 높아서 최소한의 데이터로 내 목소리를 전달가능해야함? 
	즉, 압출률이 좋아야하고,
2. 오디오 코딩
	좋은 음질, 퀄러티이 필요함.

p15
사람의 목청이 소리를 낼떄 어떤 특성이 있는지 연구.
--> voiced speech(유성음) / unvoiced speech(무성음)
유성음의 신호를 time interval

p17

사람의 목소리은 최대 4000Hz
--> Nyquist 8000Hz
--> 8000 * 8bits
--> 64kbps -> 1kbps로 높은 압축률이 가능

p18
digital audio coding

p19
아까 말한 거처럼, 사람은 20Hz~20000Hz사이까지 들을 수 있음.
신호의 세기.

사람이 듣지 못하는 신호는 의미가 없음. 
들리는 정보만 저장하고 나머지는 버림.
--> 정보의 양이 줄어듦

p20
또다른 것은 사람이 들을 수 있는 정보만이 아니라,
사람이 민감하게 듣는 Hz의 정보를 좀 더 많이 저장.

p21
이게 있었으면 들렸다면, 이게 없었따면 안들리는게 있다?
뭔 소리야 똑바로 들어
암튼 얘도 어떤 조건이면 없앤다는거같음.

p23
Temporal Masking
큰소리로 말한다음에 오는 weak sound는 또 안들리르수도 있음.

이런것들을 다 고려해서 불필요한 정보들은 다 제거하고 최대한 적은 정보로 많은 전달을 할수있게 하는거.
이게, audio인데, 그중에서 우리가 널리 쓰는 게 mp3

p27
iTunes에서는 mp3를 쓰지 않고, AAC를 씀. 
AAC가 더 좋은데 mp3를 더 많이 쓰는데, 그건 기술의 차이가 아니고, 그냥 사라들이 mp3에 많이 노출되어있어서임.

다음 시간엔 비디오 압축.
근데 그전에, p14에 ASF와 AVI, ISO, **H.264, **HEVC, MPEG-4를
보고 기억하면 좋음

container기술(말그대로 담는 기술)과 compression기술(압축하는 기술)을 구분 할 줄 알아야함.
AVI는 압축기술이 아님.

현대의 통신은 멀티미디어 통신임.
특히, 동영상 압축. 











